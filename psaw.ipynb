{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import credentials as cred\n",
    "\n",
    "username = cred.USERNAME\n",
    "client_id = cred.CLIENT_ID\n",
    "client_secret = cred.CLIENT_SECRET\n",
    "user_agent = cred.USER_AGENT\n",
    "\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent)\n",
    "api = PushshiftAPI(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "start_epoch = int(datetime().timestamp())\n",
    "end_epoch = int(datetime().timestamp())\n",
    "\n",
    "# hurricane_ida_subreddits = [\n",
    "#               'hurricaneida',\n",
    "#               'hurricane',\n",
    "#               'tropicalweather',\n",
    "#               'neworleans',\n",
    "#               'louisiana',\n",
    "#               'collapse',\n",
    "#               'publicfreakout']\n",
    "# canada_flood_subreddits = [\n",
    "#             'tropicalweather',\n",
    "#             'collapse',\n",
    "#             'publicfreakout',\n",
    "#             'canada',\n",
    "#             'britishcolumbia',\n",
    "#             'vancouver']\n",
    "# climate_related_subreddits = [\n",
    "#               'climate',\n",
    "#               'climatechange',\n",
    "#               'climateactionplan',\n",
    "#               'ecointernet',\n",
    "#               'environment',\n",
    "#               'sustainability',\n",
    "#               'weather']\n",
    "# subreddits = hurricane_ida_subreddits + climate_related_subreddits\n",
    "subreddits = []\n",
    "\n",
    "q = \"hurricane ida|hurricane|ida\"\n",
    "column_names = [\"index\", \"is_post\", \"subreddit\", \"author\", \"post_title\", \"post_text\", \n",
    "                \"num_comments\", \"score\", \"upvote_ratio\", \"flair\", \"post_url\", \"post_time\"]\n",
    "posts_table = []\n",
    "counter = 0\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    results = list(api.search_submissions(q=q, after=start_epoch,before=end_epoch,\n",
    "                            subreddit=subreddit,\n",
    "                            filter=['subreddit', 'author', 'title', 'url'],\n",
    "                            limit=1000000))\n",
    "    for p in results:\n",
    "        counter += 1\n",
    "\n",
    "        # Add the post to the table\n",
    "        posts_table.append([counter, \"yes\", p.subreddit, p.author, p.title, p.selftext, p.num_comments, p.score, p.upvote_ratio, p.link_flair_text, p.permalink,\n",
    "                            datetime.utcfromtimestamp(p.created)])\n",
    "\n",
    "        # Add the comments (only top level ones)\n",
    "        for comment in p.comments:\n",
    "            # retrieve all comments using more API calls if needed\n",
    "            p.comments.replace_more(limit=1000)\n",
    "            posts_table.append([counter, \"no\", p.subreddit, comment.author, p.title, comment.body, \"\", comment.score, \"\", \"\", comment.permalink,\n",
    "                                datetime.utcfromtimestamp(comment.created)])\n",
    "\n",
    "reddit_df = pd.DataFrame(posts_table, columns=column_names)\n",
    "reddit_df_cp = pd.DataFrame(posts_table, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df[\"post_text\"] = reddit_df[\"post_text\"].str.replace('\\n', '')\n",
    "reddit_df[\"post_title\"] = reddit_df[\"post_title\"].fillna(\"\")\n",
    "reddit_df[\"post_text\"] = reddit_df[\"post_text\"].fillna(\"\")\n",
    "reddit_df[\"flair\"] = reddit_df[\"flair\"].fillna(\"\")\n",
    "reddit_df[\"author\"] = reddit_df[\"author\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df[\"post_time_year\"] = reddit_df[\"post_time\"].apply(lambda x: x.year)\n",
    "reddit_df[\"post_time_month\"] = reddit_df[\"post_time\"].apply(lambda x: x.month)\n",
    "reddit_df[\"post_time_day\"] = reddit_df[\"post_time\"].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = reddit_df.loc[(reddit_df[\"post_text\"] == \"[deleted]\") |\n",
    "                       (reddit_df[\"post_text\"] == \"[removed]\")].index\n",
    "reddit_df.drop(reddit_df.index[labels], inplace=True)\n",
    "reddit_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit_df.to_csv(\"\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88c043b75cca8bcc76ce838030b45b32803199b8242da3d384ecf35cd9ba61d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('big-data-course': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
